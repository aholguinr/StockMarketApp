from fastapi import APIRouter, HTTPException
from backend.app.models.stock import StockRequest, StockResponse
from backend.app.services.stock_service import extraer_datos_accion


# Definici칩n del router para agrupar endpoints relacionados con "stocks"
router = APIRouter(prefix="/stocks", tags=["Stocks"])

from fastapi import APIRouter, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional
import os
import io
import pandas as pd
import matplotlib.pyplot as plt
from backend.app.services.stock_service import extraer_datos_accion, obtener_datos_accion_json  # <- ya existente
from backend.app.services.stock_analyzer import analyze_stock_decision

router = APIRouter()

# ============================
# 游늷 Modelos de request/response
# ============================

class GraficarRequest(BaseModel):
    nombre_archivo: str

class AnalizarRequest(BaseModel):
    nombre_accion: str
    fecha_final: Optional[str] = None
    dias_pasado: int = 30

class StockDecisionRequest(BaseModel):
    symbol: str = "AAPL"
    detailed_output: bool = True
    period: str = "6mo"

class StockVisualizationRequest(BaseModel):
    symbol: str
    period: str = "1mo"
    interval: str = "1d"


# ============================
# 游늷 Endpoint: Graficar acci칩n desde CSV
# ============================

@router.post("/graficar_accion")
def graficar_accion(req: GraficarRequest):
    """
    Lee un archivo CSV con datos de acciones, genera una gr치fica
    y devuelve tanto estad칤sticas en JSON como la gr치fica en PNG.
    """
    nombre_archivo = req.nombre_archivo

    # 1. Validar existencia del archivo
    if not os.path.exists(nombre_archivo):
        raise HTTPException(status_code=404, detail=f"Archivo {nombre_archivo} no encontrado")

    # 2. Leer CSV
    datos = pd.read_csv(nombre_archivo)
    if "Date" in datos.columns:
        datos["Date"] = pd.to_datetime(datos["Date"])

    # 3. Extraer metadatos del nombre de archivo
    partes = nombre_archivo.replace(".csv", "").split("-")
    simbolo = partes[0]

    # 4. Generar gr치fica en memoria
    fig, ax = plt.subplots(figsize=(12, 8))
    ax.plot(datos["Date"], datos["Close"], linewidth=2, color="#2E86C1", label="Precio de Cierre")
    ax.set_title(f"Evoluci칩n del Precio de Cierre - {simbolo}", fontsize=16, fontweight="bold", pad=20)
    ax.set_xlabel("Fecha", fontsize=12, fontweight="bold")
    ax.set_ylabel("Precio de Cierre (USD)", fontsize=12, fontweight="bold")
    ax.set_xlim(datos["Date"].min(), datos["Date"].max())
    ax.set_ylim(datos["Close"].min() * 0.98, datos["Close"].max() * 1.02)
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f"${x:.2f}"))
    plt.xticks(rotation=45)
    ax.grid(True, alpha=0.3)
    ax.legend(loc="best")
    plt.tight_layout()

    # Guardar imagen en memoria
    buffer = io.BytesIO()
    plt.savefig(buffer, format="png")
    buffer.seek(0)
    plt.close(fig)

    # 5. Calcular estad칤sticas
    precio_min = datos["Close"].min()
    precio_max = datos["Close"].max()
    precio_promedio = datos["Close"].mean()
    precio_actual = datos["Close"].iloc[-1]
    variacion = ((precio_actual - datos["Close"].iloc[0]) / datos["Close"].iloc[0]) * 100

    stats = {
        "simbolo": simbolo,
        "registros": len(datos),
        "precio_minimo": round(precio_min, 2),
        "precio_maximo": round(precio_max, 2),
        "precio_promedio": round(precio_promedio, 2),
        "precio_actual": round(precio_actual, 2),
        "variacion_porcentual": round(variacion, 2),
    }

    # 6. Devolver respuesta mixta: JSON + imagen
    headers = {"X-Stats": str(stats)}  # Metadatos en cabecera
    return StreamingResponse(buffer, media_type="image/png", headers=headers)


# ============================
# 游늷 Endpoint: An치lisis completo de acci칩n
# ============================

@router.post("/analizar_accion")
def analizar_accion(req: AnalizarRequest):
    """
    Ejecuta el flujo completo:
    - Extrae datos hist칩ricos de la acci칩n.
    - Genera una gr치fica y estad칤sticas.
    Retorna JSON con estad칤sticas + ruta del archivo generado.
    """
    try:
        # Paso 1: Extraer datos con funci칩n existente
        nombre_archivo = extraer_datos_accion(
            req.nombre_accion, req.fecha_final, req.dias_pasado
        )
        if not nombre_archivo:
            raise HTTPException(status_code=500, detail="Error al extraer datos de la acci칩n")

        # Paso 2: Graficar (reutilizando la l칩gica anterior)
        datos = pd.read_csv(nombre_archivo)
        if "Date" in datos.columns:
            datos["Date"] = pd.to_datetime(datos["Date"])

        precio_min = datos["Close"].min()
        precio_max = datos["Close"].max()
        precio_promedio = datos["Close"].mean()
        precio_actual = datos["Close"].iloc[-1]
        variacion = ((precio_actual - datos["Close"].iloc[0]) / datos["Close"].iloc[0]) * 100

        return {
            "archivo_generado": nombre_archivo,
            "estadisticas": {
                "precio_minimo": round(precio_min, 2),
                "precio_maximo": round(precio_max, 2),
                "precio_promedio": round(precio_promedio, 2),
                "precio_actual": round(precio_actual, 2),
                "variacion_porcentual": round(variacion, 2),
            },
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



@router.post("/extraer", response_model=StockResponse)
def extraer_datos(req: StockRequest):
    """
    Endpoint para extraer datos hist칩ricos de una acci칩n.

    Request:
    - nombre_accion: ticker de la acci칩n (ej: "AAPL")
    - fecha_final: fecha l칤mite en formato YYYY-MM-DD (opcional)
    - dias_pasado: n칰mero de d칤as hacia atr치s (por defecto 30)

    Response:
    - archivo_csv: nombre del archivo generado
    - mensaje: estado de la operaci칩n
    """
    try:
        archivo = extraer_datos_accion(
            nombre_accion=req.nombre_accion,
            fecha_final=req.fecha_final,
            dias_pasado=req.dias_pasado
        )
        return StockResponse(
            archivo_csv=archivo,
            mensaje="Datos extra칤dos y guardados correctamente."
        )
    except Exception as e:
        # HTTP 400 si ocurre error en la extracci칩n
        raise HTTPException(status_code=400, detail=str(e))


# ============================
# 游늷 Endpoint: An치lisis de decisi칩n de inversi칩n
# ============================

@router.post("/stocks/analyze_decision")
def analyze_stock_investment_decision(req: StockDecisionRequest):
    """
    Realiza un an치lisis completo de una acci칩n para tomar decisiones de inversi칩n.
    
    Request:
    - symbol: S칤mbolo de la acci칩n (ej: "AAPL", "TSLA")
    - detailed_output: True para an치lisis completo, False para resumen
    - period: Per칤odo de datos hist칩ricos ("6mo", "1y", "2y")
    
    Response:
    - An치lisis completo con recomendaci칩n de compra/venta/mantener
    - Indicadores t칠cnicos, momentum, patrones estad칤sticos
    - M칠tricas de riesgo y niveles de precios
    """
    try:
        analysis_result = analyze_stock_decision(
            symbol=req.symbol,
            detailed_output=req.detailed_output,
            period=req.period
        )
        
        # Verificar si hay error en el an치lisis
        if "error" in analysis_result:
            raise HTTPException(status_code=400, detail=analysis_result["error"])
        
        return analysis_result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error en el an치lisis: {str(e)}")


# ============================
# 游늷 Endpoint: Visualizaci칩n de acciones con intervalos
# ============================

@router.post("/stocks/get_stock_data")
def get_stock_data_for_visualization(req: StockVisualizationRequest):
    """
    Obtiene datos hist칩ricos de una acci칩n para visualizaci칩n con intervalos flexibles.
    
    Request:
    - symbol: S칤mbolo de la acci칩n (ej: "AAPL", "TSLA")
    - period: Per칤odo de datos ("1d", "5d", "1mo", "3mo", "6mo", "1y", "2y", "5y", "10y", "ytd", "max")
    - interval: Intervalo de tiempo ("1m", "2m", "5m", "15m", "30m", "60m", "90m", "1h", "1d", "5d", "1wk", "1mo", "3mo")
    
    Response:
    - Datos hist칩ricos en formato JSON con informaci칩n de la empresa
    - Datos preparados para gr치ficas (fechas, precios, volumen)
    """
    try:
        # Validar inputs
        if not req.symbol or len(req.symbol.strip()) == 0:
            raise HTTPException(status_code=400, detail="S칤mbolo de acci칩n requerido")
        
        # Obtener datos usando la funci칩n actualizada
        result = obtener_datos_accion_json(
            nombre_accion=req.symbol,
            periodo=req.period,
            intervalo=req.interval
        )
        
        return result
        
    except ValueError as e:
        raise HTTPException(status_code=400, detail=str(e))
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error al obtener datos: {str(e)}")


@router.get("/get_available_intervals")
def get_available_intervals():
    """
    Retorna los intervalos y per칤odos disponibles para la visualizaci칩n.
    
    Response:
    - Lista de intervalos v치lidos
    - Lista de per칤odos v치lidos
    - Restricciones por intervalo
    """
    return {
        "intervals": {
            "minutes": ["1m", "2m", "5m", "15m", "30m", "60m", "90m"],
            "hours": ["1h"],
            "days": ["1d", "5d"],
            "weeks": ["1wk"],
            "months": ["1mo", "3mo"]
        },
        "periods": {
            "short_term": ["1d", "5d"],
            "medium_term": ["1mo", "3mo", "6mo"],
            "long_term": ["1y", "2y", "5y", "10y"],
            "special": ["ytd", "max"]
        },
        "restrictions": {
            "minute_intervals": {
                "allowed_intervals": ["1m", "2m", "5m", "15m", "30m", "60m", "90m"],
                "allowed_periods": ["1d", "5d"],
                "max_days": 7
            },
            "hour_intervals": {
                "allowed_intervals": ["1h"],
                "allowed_periods": ["1d", "5d", "1mo", "3mo", "6mo", "1y", "2y"],
                "max_days": 730
            },
            "day_or_larger": {
                "allowed_intervals": ["1d", "5d", "1wk", "1mo", "3mo"],
                "allowed_periods": "all",
                "max_days": "unlimited"
            }
        },
        "recommendations": {
            "intraday_trading": {"interval": "1m", "period": "1d"},
            "day_trading": {"interval": "5m", "period": "5d"},
            "swing_trading": {"interval": "1h", "period": "1mo"},
            "position_trading": {"interval": "1d", "period": "1y"},
            "long_term_analysis": {"interval": "1wk", "period": "5y"}
        }
    }


# ============================
# 游늷 ETF Analysis Module
# ============================

# ETF Categories and Data
MAJOR_ETFS = {
    'broad_market': {
        'name': 'Mercado Amplio',
        'description': 'ETFs que siguen 칤ndices amplios del mercado estadounidense',
        'etfs': {
            'SPY': 'SPDR S&P 500 ETF - Sigue el 칤ndice S&P 500',
            'VOO': 'Vanguard S&P 500 ETF - Versi칩n de bajo costo del S&P 500',
            'IVV': 'iShares Core S&P 500 ETF - Otra opci칩n para el S&P 500',
            'VTI': 'Vanguard Total Stock Market ETF - Todo el mercado de EE.UU.',
            'ITOT': 'iShares Core S&P Total U.S. Stock Market ETF'
        }
    },
    'international': {
        'name': 'Internacional',
        'description': 'ETFs de mercados internacionales desarrollados y emergentes',
        'etfs': {
            'VEA': 'Vanguard FTSE Developed Markets ETF - Mercados desarrollados',
            'IEFA': 'iShares Core MSCI EAFE IMI Index ETF',
            'VWO': 'Vanguard FTSE Emerging Markets ETF - Mercados emergentes',
            'EEM': 'iShares MSCI Emerging Markets ETF',
            'IEMG': 'iShares Core MSCI Emerging Markets IMI Index ETF'
        }
    },
    'bonds': {
        'name': 'Bonos',
        'description': 'ETFs de renta fija y bonos gubernamentales/corporativos',
        'etfs': {
            'BND': 'Vanguard Total Bond Market ETF - Bonos totales',
            'AGG': 'iShares Core U.S. Aggregate Bond ETF',
            'VGIT': 'Vanguard Intermediate-Term Treasury ETF',
            'IUSB': 'iShares Core Total USD Bond Market ETF',
            'SCHZ': 'Schwab Intermediate-Term U.S. Treasury ETF'
        }
    },
    'sectors': {
        'name': 'Sectores SPDR',
        'description': 'ETFs que siguen sectores espec칤ficos del S&P 500',
        'etfs': {
            'XLK': 'Technology Select Sector SPDR Fund - Tecnolog칤a',
            'XLF': 'Financial Select Sector SPDR Fund - Financiero',
            'XLE': 'Energy Select Sector SPDR Fund - Energ칤a',
            'XLV': 'Health Care Select Sector SPDR Fund - Salud',
            'XLI': 'Industrial Select Sector SPDR Fund - Industrial',
            'XLP': 'Consumer Staples Select Sector SPDR Fund - Consumo b치sico',
            'XLY': 'Consumer Discretionary Select Sector SPDR Fund - Consumo discrecional',
            'XLU': 'Utilities Select Sector SPDR Fund - Servicios p칰blicos',
            'XLB': 'Materials Select Sector SPDR Fund - Materiales',
            'XLRE': 'Real Estate Select Sector SPDR Fund - Bienes ra칤ces',
            'XLC': 'Communication Services Select Sector SPDR Fund - Comunicaciones'
        }
    },
    'commodities': {
        'name': 'Commodities',
        'description': 'ETFs de materias primas y metales preciosos',
        'etfs': {
            'GLD': 'SPDR Gold Shares - Oro',
            'SLV': 'iShares Silver Trust - Plata',
            'USO': 'United States Oil Fund - Petr칩leo',
            'DBA': 'Invesco DB Agriculture Fund - Agricultura',
            'PDBC': 'Invesco Optimum Yield Diversified Commodity Strategy'
        }
    },
    'real_estate': {
        'name': 'Bienes Ra칤ces',
        'description': 'ETFs de REITs y bienes ra칤ces',
        'etfs': {
            'VNQ': 'Vanguard Real Estate ETF - REITs',
            'SCHH': 'Schwab U.S. REIT ETF',
            'FREL': 'Fidelity MSCI Real Estate Index ETF',
            'RWR': 'SPDR Dow Jones REIT ETF'
        }
    },
    'volatility': {
        'name': 'Volatilidad',
        'description': 'ETFs relacionados con la volatilidad del mercado',
        'etfs': {
            'UVXY': 'ProShares Ultra VIX Short-Term Futures ETF',
            'SVXY': 'ProShares Short VIX Short-Term Futures ETF'
        }
    },
    'thematic': {
        'name': 'Tem치ticos',
        'description': 'ETFs de tendencias y temas espec칤ficos',
        'etfs': {
            'NLR': 'VanEck Nuclear Energy ETF - Energ칤a nuclear',
            'ICLN': 'iShares Global Clean Energy ETF - Energ칤a limpia',
            'ARKK': 'ARK Innovation ETF - Innovaci칩n disruptiva',
            'SOXX': 'iShares Semiconductor ETF - Semiconductores',
            'XBI': 'SPDR S&P Biotech ETF - Biotecnolog칤a',
            'HACK': 'ETFMG Prime Cyber Security ETF - Ciberseguridad',
            'ROBO': 'ROBO Global Robotics and Automation ETF',
            'ESPO': 'VanEck Gaming ETF - Gaming y esports'
        }
    }
}

class ETFAnalysisRequest(BaseModel):
    etfs: list[str] = []
    period: str = "1y"
    interval: str = "1d"
    include_summary: bool = True

class CustomETFRequest(BaseModel):
    symbol: str
    name: str
    description: str
    category: str = "custom"

class MultiStockAnalysisRequest(BaseModel):
    symbols: list[str]
    period: str = "6mo"
    detailed_output: bool = True
    normalize: bool = False

@router.get("/etfs/categories")
def get_etf_categories():
    """
    Retorna todas las categor칤as de ETFs con sus descripciones.
    """
    return {
        "categories": MAJOR_ETFS,
        "total_etfs": sum(len(cat["etfs"]) for cat in MAJOR_ETFS.values())
    }

@router.post("/etfs/analyze")
def analyze_etfs(req: ETFAnalysisRequest):
    """
    Analiza m칰ltiples ETFs y retorna datos de comparaci칩n.
    
    Request:
    - etfs: Lista de s칤mbolos de ETFs a analizar
    - period: Per칤odo de an치lisis
    - interval: Intervalo de datos
    - include_summary: Si incluir resumen de indicadores
    """
    try:
        results = {}
        
        # Lista de s칤mbolos problem치ticos conocidos que deben ser omitidos silenciosamente
        problematic_symbols = {'VIX'}  # VIX ya no deber칤a estar pero por seguridad
        
        for etf_symbol in req.etfs:
            # Saltar s칤mbolos problem치ticos conocidos
            if etf_symbol in problematic_symbols:
                print(f"Skipping problematic symbol: {etf_symbol}")
                continue
                
            try:
                # Usar la funci칩n existente para obtener datos con timeout impl칤cito
                etf_data = obtener_datos_accion_json(
                    nombre_accion=etf_symbol,
                    periodo=req.period,
                    intervalo=req.interval
                )
                
                # Validar que tenemos datos v치lidos
                if not etf_data or "data" not in etf_data or not etf_data["data"]:
                    results[etf_symbol] = {"error": f"No hay datos disponibles para {etf_symbol}"}
                    continue
                
                if req.include_summary:
                    # Calcular indicadores clave
                    data_points = etf_data["data"]
                    if data_points:
                        prices = [point["Close"] for point in data_points if point["Close"] and point["Close"] > 0]
                        volumes = [point["Volume"] for point in data_points if point["Volume"] and point["Volume"] > 0]
                        
                        if len(prices) > 1:
                            # Calcular m칠tricas
                            current_price = prices[-1]
                            start_price = prices[0]
                            returns = [(prices[i] / prices[i-1] - 1) * 100 for i in range(1, len(prices))]
                            
                            summary = {
                                "current_price": round(current_price, 2),
                                "total_return": round(((current_price / start_price) - 1) * 100, 2),
                                "volatility": round(pd.Series(returns).std(), 2) if len(returns) > 1 else 0,
                                "avg_volume": int(sum(volumes) / len(volumes)) if volumes else 0,
                                "max_price": round(max(prices), 2),
                                "min_price": round(min(prices), 2),
                                "data_points": len(prices)
                            }
                            etf_data["summary"] = summary
                        else:
                            results[etf_symbol] = {"error": f"Datos insuficientes para {etf_symbol}"}
                            continue
                
                results[etf_symbol] = etf_data
                
            except Exception as e:
                error_msg = str(e).lower()
                # Detectar errores comunes y dar mensajes m치s espec칤ficos
                if "delisted" in error_msg or "no price data" in error_msg:
                    results[etf_symbol] = {"error": f"ETF {etf_symbol} no disponible o descontinuado"}
                elif "timeout" in error_msg:
                    results[etf_symbol] = {"error": f"Timeout obteniendo datos para {etf_symbol}"}
                else:
                    results[etf_symbol] = {"error": f"Error obteniendo datos para {etf_symbol}: {str(e)}"}
        
        return {
            "success": True,
            "period": req.period,
            "interval": req.interval,
            "analyzed_etfs": len(req.etfs),
            "results": results
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error en an치lisis de ETFs: {str(e)}")

@router.get("/etfs/summary/{period}")
def get_etfs_summary(period: str = "1mo"):
    """
    Obtiene un resumen r치pido de todos los ETFs principales.
    
    Parameters:
    - period: Per칤odo para el c치lculo de m칠tricas (1mo, 3mo, 6mo, 1y)
    """
    try:
        all_etfs = []
        for category_name, category_data in MAJOR_ETFS.items():
            for etf_symbol in category_data["etfs"].keys():
                all_etfs.append(etf_symbol)
        
        # Analizar todos los ETFs
        req = ETFAnalysisRequest(
            etfs=all_etfs,
            period=period,
            interval="1d",
            include_summary=True
        )
        
        analysis = analyze_etfs(req)
        
        # Reorganizar por categor칤as, solo incluyendo ETFs con datos v치lidos
        categorized_summary = {}
        for category_name, category_data in MAJOR_ETFS.items():
            categorized_summary[category_name] = {
                "name": category_data["name"],
                "description": category_data["description"],
                "etfs": {}
            }
            
            for etf_symbol, etf_description in category_data["etfs"].items():
                if (etf_symbol in analysis["results"] and 
                    "summary" in analysis["results"][etf_symbol] and 
                    "error" not in analysis["results"][etf_symbol]):
                    categorized_summary[category_name]["etfs"][etf_symbol] = {
                        "description": etf_description,
                        "summary": analysis["results"][etf_symbol]["summary"]
                    }
                # Si hay error, simplemente no incluir el ETF en el resumen para no confundir al usuario
        
        return {
            "success": True,
            "period": period,
            "generated_at": pd.Timestamp.now().isoformat(),
            "categories": categorized_summary
        }
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error generando resumen de ETFs: {str(e)}")


# ============================
# 游늷 Multi-Stock Analysis Module
# ============================

@router.post("/stocks/analyze_multiple")
def analyze_multiple_stocks(req: MultiStockAnalysisRequest):
    """
    Analiza m칰ltiples acciones y proporciona comparaci칩n y recomendaciones globales.
    
    Request:
    - symbols: Lista de s칤mbolos de acciones (m치ximo 10)
    - period: Per칤odo de an치lisis
    - detailed_output: Si incluir an치lisis detallado
    - normalize: Si normalizar valores para comparaci칩n
    
    Response:
    - An치lisis individual de cada acci칩n
    - Tabla comparativa
    - Recomendaciones globales
    - M칠tricas de portafolio
    """
    try:
        # Validar n칰mero de s칤mbolos
        if len(req.symbols) > 10:
            raise HTTPException(status_code=400, detail="M치ximo 10 acciones permitidas")
        
        if len(req.symbols) == 0:
            raise HTTPException(status_code=400, detail="Debe proporcionar al menos una acci칩n")
        
        # Eliminar duplicados y limpiar s칤mbolos
        unique_symbols = list(dict.fromkeys([symbol.upper().strip() for symbol in req.symbols if symbol.strip()]))
        
        if len(unique_symbols) == 0:
            raise HTTPException(status_code=400, detail="No se proporcionaron s칤mbolos v치lidos")
        
        results = {}
        successful_analyses = []
        failed_analyses = []
        
        # Analizar cada acci칩n individualmente
        for symbol in unique_symbols:
            try:
                # Usar la funci칩n existente de an치lisis
                individual_analysis = analyze_stock_decision(
                    symbol=symbol,
                    detailed_output=req.detailed_output,
                    period=req.period
                )
                
                if "error" not in individual_analysis:
                    results[symbol] = individual_analysis
                    successful_analyses.append(symbol)
                else:
                    failed_analyses.append({"symbol": symbol, "error": individual_analysis["error"]})
                    
            except Exception as e:
                failed_analyses.append({"symbol": symbol, "error": str(e)})
        
        if len(successful_analyses) == 0:
            raise HTTPException(status_code=400, detail="No se pudo analizar ninguna acci칩n exitosamente")
        
        # Generar an치lisis comparativo
        comparative_analysis = generate_comparative_analysis(results, req.normalize)
        
        # Generar recomendaciones globales
        global_recommendations = generate_global_recommendations(results, comparative_analysis)
        
        return {
            "success": True,
            "period": req.period,
            "total_requested": len(unique_symbols),
            "successful_analyses": len(successful_analyses),
            "failed_analyses": len(failed_analyses),
            "individual_results": results,
            "comparative_analysis": comparative_analysis,
            "global_recommendations": global_recommendations,
            "failed_symbols": failed_analyses,
            "normalized": req.normalize
        }
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error en an치lisis m칰ltiple: {str(e)}")


def generate_comparative_analysis(results, normalize=False):
    """
    Genera an치lisis comparativo entre m칰ltiples acciones.
    """
    if not results:
        return {}
    
    # Extraer m칠tricas clave de cada acci칩n
    comparison_table = []
    
    for symbol, data in results.items():
        try:
            row = {
                "symbol": symbol,
                "current_price": float(data.get("current_price", 0)),
                "recommendation": data.get("recommendation", "N/A"),
                "confidence": float(data.get("confidence", 0)),
                "entry_price": float(data.get("entry_price", 0)),
                "stop_loss": float(data.get("stop_loss", 0)),
                "take_profit": float(data.get("take_profit", 0)),
                "risk_level": data.get("risk_level", "N/A"),
                "final_score": float(data.get("scoring_breakdown", {}).get("final_score", 0)),
                "technical_score": float(data.get("scoring_breakdown", {}).get("technical_score", 0)),
                "momentum_score": float(data.get("scoring_breakdown", {}).get("momentum_score", 0)),
                "risk_score": float(data.get("scoring_breakdown", {}).get("risk_score", 0)),
                "sharpe_ratio": float(data.get("risk_metrics", {}).get("sharpe_ratio", 0)),
                "volatility": float(data.get("risk_metrics", {}).get("daily_volatility", 0)),
                "max_drawdown": float(data.get("risk_metrics", {}).get("max_drawdown", 0))
            }
            
            comparison_table.append(row)
            
        except (ValueError, TypeError) as e:
            print(f"Error processing {symbol}: {e}")
            continue
    
    if not comparison_table:
        return {"error": "No se pudieron procesar los datos para comparaci칩n"}
    
    # Normalizar valores si se solicita
    if normalize and len(comparison_table) > 1:
        comparison_table = normalize_values(comparison_table)
    
    # Calcular estad칤sticas del grupo
    scores = [row["final_score"] for row in comparison_table if row["final_score"] > 0]
    confidences = [row["confidence"] for row in comparison_table if row["confidence"] > 0]
    volatilities = [row["volatility"] for row in comparison_table if row["volatility"] > 0]
    
    group_stats = {
        "avg_score": round(sum(scores) / len(scores), 2) if scores else 0,
        "max_score": max(scores) if scores else 0,
        "min_score": min(scores) if scores else 0,
        "avg_confidence": round(sum(confidences) / len(confidences), 2) if confidences else 0,
        "avg_volatility": round(sum(volatilities) / len(volatilities), 2) if volatilities else 0,
        "best_performer": max(comparison_table, key=lambda x: x["final_score"])["symbol"] if comparison_table else None,
        "worst_performer": min(comparison_table, key=lambda x: x["final_score"])["symbol"] if comparison_table else None
    }
    
    # Ranking por diferentes criterios
    rankings = {
        "by_score": sorted(comparison_table, key=lambda x: x["final_score"], reverse=True),
        "by_confidence": sorted(comparison_table, key=lambda x: x["confidence"], reverse=True),
        "by_sharpe_ratio": sorted(comparison_table, key=lambda x: x["sharpe_ratio"], reverse=True),
        "by_risk_adjusted": sorted(comparison_table, key=lambda x: x["final_score"] / max(x["volatility"], 1), reverse=True)
    }
    
    return {
        "comparison_table": comparison_table,
        "group_statistics": group_stats,
        "rankings": rankings,
        "total_stocks": len(comparison_table)
    }


def normalize_values(data):
    """
    Normaliza valores num칠ricos para comparaci칩n objetiva (0-100 scale).
    """
    if len(data) <= 1:
        return data
    
    # Campos a normalizar
    fields_to_normalize = [
        "final_score", "technical_score", "momentum_score", 
        "risk_score", "confidence", "sharpe_ratio"
    ]
    
    normalized_data = []
    
    for row in data:
        normalized_row = row.copy()
        
        for field in fields_to_normalize:
            values = [r.get(field, 0) for r in data if r.get(field) is not None]
            
            if len(values) > 1 and max(values) != min(values):
                # Min-max normalization to 0-100 scale
                min_val = min(values)
                max_val = max(values)
                current_val = row.get(field, 0)
                
                normalized_val = ((current_val - min_val) / (max_val - min_val)) * 100
                normalized_row[f"{field}_normalized"] = round(normalized_val, 2)
            else:
                normalized_row[f"{field}_normalized"] = row.get(field, 0)
        
        normalized_data.append(normalized_row)
    
    return normalized_data


def generate_global_recommendations(results, comparative_analysis):
    """
    Genera recomendaciones globales basadas en el an치lisis de m칰ltiples acciones.
    """
    if not results or not comparative_analysis.get("comparison_table"):
        return {"error": "Datos insuficientes para recomendaciones globales"}
    
    comparison_table = comparative_analysis["comparison_table"]
    group_stats = comparative_analysis["group_statistics"]
    
    # An치lisis de distribuci칩n de recomendaciones
    recommendations = [row["recommendation"] for row in comparison_table]
    rec_counts = {}
    for rec in recommendations:
        rec_counts[rec] = rec_counts.get(rec, 0) + 1
    
    # Acciones con mejor puntuaci칩n
    top_performers = sorted(comparison_table, key=lambda x: x["final_score"], reverse=True)[:3]
    
    # Acciones de alto riesgo
    high_risk_stocks = [row for row in comparison_table if row["risk_level"] == "ALTO"]
    
    # Acciones con mejor ratio riesgo-retorno
    best_risk_adjusted = sorted(
        comparison_table, 
        key=lambda x: x["final_score"] / max(x["volatility"], 1), 
        reverse=True
    )[:3]
    
    # Generar recomendaciones de portafolio (para uso futuro)
    # portfolio_recommendations = []
    
    # Estrategia conservadora
    conservative_picks = [
        row for row in comparison_table 
        if row["risk_level"] in ["BAJO", "MEDIO"] and row["confidence"] >= 70
    ]
    
    # Estrategia agresiva
    aggressive_picks = [
        row for row in comparison_table 
        if row["final_score"] >= group_stats["avg_score"] and row["recommendation"] == "COMPRAR"
    ]
    
    # Diversificaci칩n por niveles de riesgo
    risk_distribution = {}
    for row in comparison_table:
        risk_level = row["risk_level"]
        risk_distribution[risk_level] = risk_distribution.get(risk_level, 0) + 1
    
    # Recomendaciones espec칤ficas
    specific_recommendations = []
    
    if len(top_performers) > 0:
        specific_recommendations.append({
            "type": "top_pick",
            "title": "Mejor Oportunidad",
            "symbol": top_performers[0]["symbol"],
            "reason": f"Mayor puntuaci칩n ({top_performers[0]['final_score']}) y confianza del {top_performers[0]['confidence']}%"
        })
    
    if len(conservative_picks) > 0:
        specific_recommendations.append({
            "type": "conservative",
            "title": "Opci칩n Conservadora",
            "symbols": [stock["symbol"] for stock in conservative_picks[:2]],
            "reason": "Bajo riesgo con buena confianza en la recomendaci칩n"
        })
    
    if len(best_risk_adjusted) > 0:
        specific_recommendations.append({
            "type": "risk_adjusted",
            "title": "Mejor Ratio Riesgo-Retorno",
            "symbol": best_risk_adjusted[0]["symbol"],
            "reason": "칍ptima relaci칩n entre puntuaci칩n y volatilidad"
        })
    
    # Alertas y warnings
    alerts = []
    
    if len(high_risk_stocks) > len(comparison_table) * 0.5:
        alerts.append({
            "type": "warning",
            "message": "M치s del 50% de las acciones presentan alto riesgo. Considere diversificar."
        })
    
    if group_stats["avg_confidence"] < 60:
        alerts.append({
            "type": "caution",
            "message": f"Confianza promedio baja ({group_stats['avg_confidence']}%). Mercado vol치til o datos limitados."
        })
    
    if rec_counts.get("VENDER", 0) > rec_counts.get("COMPRAR", 0):
        alerts.append({
            "type": "bearish",
            "message": "Predominan se침ales de venta. Considere estrategias defensivas."
        })
    
    return {
        "portfolio_score": round(group_stats["avg_score"], 2),
        "recommendation_distribution": rec_counts,
        "top_performers": [stock["symbol"] for stock in top_performers],
        "risk_distribution": risk_distribution,
        "conservative_options": [stock["symbol"] for stock in conservative_picks],
        "aggressive_options": [stock["symbol"] for stock in aggressive_picks],
        "specific_recommendations": specific_recommendations,
        "alerts": alerts,
        "summary": {
            "best_pick": top_performers[0]["symbol"] if top_performers else None,
            "portfolio_strength": "FUERTE" if group_stats["avg_score"] >= 70 else "MODERADA" if group_stats["avg_score"] >= 50 else "D칄BIL",
            "diversification_score": min(len(set(recommendations)), 3) * 33.33,  # Max 100% if all 3 rec types present
            "overall_recommendation": "COMPRAR" if rec_counts.get("COMPRAR", 0) > len(comparison_table) * 0.5 else "MANTENER"
        }
    }
